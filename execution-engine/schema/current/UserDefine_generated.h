// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_USERDEFINE_MNN_H_
#define FLATBUFFERS_GENERATED_USERDEFINE_MNN_H_


#include "CaffeOp_generated.h"
#include "Tensor_generated.h"
#include "Type_generated.h"

namespace MNN {

struct TensorConvertInfo;
struct TensorConvertInfoT;

struct GridSample;
struct GridSampleT;

struct NITI_CONV_Int8;
struct NITI_CONV_Int8T;

struct NITI_Relu_Int8;
struct NITI_Relu_Int8T;

struct NITI_Pool_Int8;
struct NITI_Pool_Int8T;

struct NITI_ELTWISE_Int8;
struct NITI_ELTWISE_Int8T;

struct NITI_LOSS_Int8;
struct NITI_LOSS_Int8T;

struct NITI_PAD_Int8;
struct NITI_PAD_Int8T;

inline const flatbuffers::TypeTable *TensorConvertInfoTypeTable();

inline const flatbuffers::TypeTable *GridSampleTypeTable();

inline const flatbuffers::TypeTable *NITI_CONV_Int8TypeTable();

inline const flatbuffers::TypeTable *NITI_Relu_Int8TypeTable();

inline const flatbuffers::TypeTable *NITI_Pool_Int8TypeTable();

inline const flatbuffers::TypeTable *NITI_ELTWISE_Int8TypeTable();

inline const flatbuffers::TypeTable *NITI_LOSS_Int8TypeTable();

inline const flatbuffers::TypeTable *NITI_PAD_Int8TypeTable();

enum SampleMode {
  SampleMode_BILINEAR = 0,
  SampleMode_NEAREST = 1,
  SampleMode_MIN = SampleMode_BILINEAR,
  SampleMode_MAX = SampleMode_NEAREST
};

inline const SampleMode (&EnumValuesSampleMode())[2] {
  static const SampleMode values[] = {
    SampleMode_BILINEAR,
    SampleMode_NEAREST
  };
  return values;
}

inline const char * const *EnumNamesSampleMode() {
  static const char * const names[] = {
    "BILINEAR",
    "NEAREST",
    nullptr
  };
  return names;
}

inline const char *EnumNameSampleMode(SampleMode e) {
  if (e < SampleMode_BILINEAR || e > SampleMode_NEAREST) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesSampleMode()[index];
}

enum BorderMode {
  BorderMode_ZEROS = 0,
  BorderMode_CLAMP = 1,
  BorderMode_REFLECTION = 2,
  BorderMode_MIN = BorderMode_ZEROS,
  BorderMode_MAX = BorderMode_REFLECTION
};

inline const BorderMode (&EnumValuesBorderMode())[3] {
  static const BorderMode values[] = {
    BorderMode_ZEROS,
    BorderMode_CLAMP,
    BorderMode_REFLECTION
  };
  return values;
}

inline const char * const *EnumNamesBorderMode() {
  static const char * const names[] = {
    "ZEROS",
    "CLAMP",
    "REFLECTION",
    nullptr
  };
  return names;
}

inline const char *EnumNameBorderMode(BorderMode e) {
  if (e < BorderMode_ZEROS || e > BorderMode_REFLECTION) return "";
  const size_t index = static_cast<int>(e);
  return EnumNamesBorderMode()[index];
}

struct TensorConvertInfoT : public flatbuffers::NativeTable {
  typedef TensorConvertInfo TableType;
  MNN_DATA_FORMAT source;
  MNN_DATA_FORMAT dest;
  TensorConvertInfoT()
      : source(MNN_DATA_FORMAT_NCHW),
        dest(MNN_DATA_FORMAT_NCHW) {
  }
};

struct TensorConvertInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorConvertInfoT NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return TensorConvertInfoTypeTable();
  }
  MNN_DATA_FORMAT source() const {
    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(4, 0));
  }
  MNN_DATA_FORMAT dest() const {
    return static_cast<MNN_DATA_FORMAT>(GetField<int8_t>(6, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, 4) &&
           VerifyField<int8_t>(verifier, 6) &&
           verifier.EndTable();
  }
  TensorConvertInfoT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(TensorConvertInfoT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<TensorConvertInfo> Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct TensorConvertInfoBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_source(MNN_DATA_FORMAT source) {
    fbb_.AddElement<int8_t>(4, static_cast<int8_t>(source), 0);
  }
  void add_dest(MNN_DATA_FORMAT dest) {
    fbb_.AddElement<int8_t>(6, static_cast<int8_t>(dest), 0);
  }
  explicit TensorConvertInfoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorConvertInfoBuilder &operator=(const TensorConvertInfoBuilder &);
  flatbuffers::Offset<TensorConvertInfo> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorConvertInfo>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(
    flatbuffers::FlatBufferBuilder &_fbb,
    MNN_DATA_FORMAT source = MNN_DATA_FORMAT_NCHW,
    MNN_DATA_FORMAT dest = MNN_DATA_FORMAT_NCHW) {
  TensorConvertInfoBuilder builder_(_fbb);
  builder_.add_dest(dest);
  builder_.add_source(source);
  return builder_.Finish();
}

flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct GridSampleT : public flatbuffers::NativeTable {
  typedef GridSample TableType;
  SampleMode mode;
  BorderMode paddingMode;
  bool alignCorners;
  GridSampleT()
      : mode(SampleMode_BILINEAR),
        paddingMode(BorderMode_ZEROS),
        alignCorners(false) {
  }
};

struct GridSample FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef GridSampleT NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return GridSampleTypeTable();
  }
  SampleMode mode() const {
    return static_cast<SampleMode>(GetField<int8_t>(4, 0));
  }
  BorderMode paddingMode() const {
    return static_cast<BorderMode>(GetField<int8_t>(6, 0));
  }
  bool alignCorners() const {
    return GetField<uint8_t>(8, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, 4) &&
           VerifyField<int8_t>(verifier, 6) &&
           VerifyField<uint8_t>(verifier, 8) &&
           verifier.EndTable();
  }
  GridSampleT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(GridSampleT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<GridSample> Pack(flatbuffers::FlatBufferBuilder &_fbb, const GridSampleT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct GridSampleBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_mode(SampleMode mode) {
    fbb_.AddElement<int8_t>(4, static_cast<int8_t>(mode), 0);
  }
  void add_paddingMode(BorderMode paddingMode) {
    fbb_.AddElement<int8_t>(6, static_cast<int8_t>(paddingMode), 0);
  }
  void add_alignCorners(bool alignCorners) {
    fbb_.AddElement<uint8_t>(8, static_cast<uint8_t>(alignCorners), 0);
  }
  explicit GridSampleBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  GridSampleBuilder &operator=(const GridSampleBuilder &);
  flatbuffers::Offset<GridSample> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<GridSample>(end);
    return o;
  }
};

inline flatbuffers::Offset<GridSample> CreateGridSample(
    flatbuffers::FlatBufferBuilder &_fbb,
    SampleMode mode = SampleMode_BILINEAR,
    BorderMode paddingMode = BorderMode_ZEROS,
    bool alignCorners = false) {
  GridSampleBuilder builder_(_fbb);
  builder_.add_alignCorners(alignCorners);
  builder_.add_paddingMode(paddingMode);
  builder_.add_mode(mode);
  return builder_.Finish();
}

flatbuffers::Offset<GridSample> CreateGridSample(flatbuffers::FlatBufferBuilder &_fbb, const GridSampleT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_CONV_Int8T : public flatbuffers::NativeTable {
  typedef NITI_CONV_Int8 TableType;
  std::unique_ptr<Convolution2DCommonT> common;
  std::vector<int8_t> weight;
  int8_t wscale;
  int8_t nbits;
  NITI_CONV_Int8T()
      : wscale(0),
        nbits(0) {
  }
};

struct NITI_CONV_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_CONV_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_CONV_Int8TypeTable();
  }
  const Convolution2DCommon *common() const {
    return GetPointer<const Convolution2DCommon *>(4);
  }
  const flatbuffers::Vector<int8_t> *weight() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(6);
  }
  int8_t wscale() const {
    return GetField<int8_t>(8, 0);
  }
  int8_t nbits() const {
    return GetField<int8_t>(10, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, 4) &&
           verifier.VerifyTable(common()) &&
           VerifyOffset(verifier, 6) &&
           verifier.VerifyVector(weight()) &&
           VerifyField<int8_t>(verifier, 8) &&
           VerifyField<int8_t>(verifier, 10) &&
           verifier.EndTable();
  }
  NITI_CONV_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_CONV_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_CONV_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_CONV_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_CONV_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_common(flatbuffers::Offset<Convolution2DCommon> common) {
    fbb_.AddOffset(4, common);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::Vector<int8_t>> weight) {
    fbb_.AddOffset(6, weight);
  }
  void add_wscale(int8_t wscale) {
    fbb_.AddElement<int8_t>(8, wscale, 0);
  }
  void add_nbits(int8_t nbits) {
    fbb_.AddElement<int8_t>(10, nbits, 0);
  }
  explicit NITI_CONV_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_CONV_Int8Builder &operator=(const NITI_CONV_Int8Builder &);
  flatbuffers::Offset<NITI_CONV_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_CONV_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_CONV_Int8> CreateNITI_CONV_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<Convolution2DCommon> common = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> weight = 0,
    int8_t wscale = 0,
    int8_t nbits = 0) {
  NITI_CONV_Int8Builder builder_(_fbb);
  builder_.add_weight(weight);
  builder_.add_common(common);
  builder_.add_nbits(nbits);
  builder_.add_wscale(wscale);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_CONV_Int8> CreateNITI_CONV_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_CONV_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_Relu_Int8T : public flatbuffers::NativeTable {
  typedef NITI_Relu_Int8 TableType;
  DataType dataType;
  NITI_Relu_Int8T()
      : dataType(DataType_DT_INT8) {
  }
};

struct NITI_Relu_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_Relu_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_Relu_Int8TypeTable();
  }
  DataType dataType() const {
    return static_cast<DataType>(GetField<int32_t>(4, 6));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, 4) &&
           verifier.EndTable();
  }
  NITI_Relu_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_Relu_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_Relu_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Relu_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_Relu_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_dataType(DataType dataType) {
    fbb_.AddElement<int32_t>(4, static_cast<int32_t>(dataType), 6);
  }
  explicit NITI_Relu_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_Relu_Int8Builder &operator=(const NITI_Relu_Int8Builder &);
  flatbuffers::Offset<NITI_Relu_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_Relu_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_Relu_Int8> CreateNITI_Relu_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    DataType dataType = DataType_DT_INT8) {
  NITI_Relu_Int8Builder builder_(_fbb);
  builder_.add_dataType(dataType);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_Relu_Int8> CreateNITI_Relu_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Relu_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_Pool_Int8T : public flatbuffers::NativeTable {
  typedef NITI_Pool_Int8 TableType;
  int32_t padX;
  int32_t padY;
  bool isGlobal;
  int32_t kernelX;
  int32_t kernelY;
  int32_t strideX;
  int32_t strideY;
  PoolType type;
  PoolPadType padType;
  DataType dataType;
  bool ceilModel;
  std::vector<int32_t> pads;
  AvgPoolCountType countType;
  int32_t ow;
  int32_t oh;
  NITI_Pool_Int8T()
      : padX(0),
        padY(0),
        isGlobal(false),
        kernelX(0),
        kernelY(0),
        strideX(0),
        strideY(0),
        type(PoolType_MAXPOOL),
        padType(PoolPadType_CAFFE),
        dataType(DataType_DT_FLOAT),
        ceilModel(true),
        countType(AvgPoolCountType_DEFAULT),
        ow(0),
        oh(0) {
  }
};

struct NITI_Pool_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_Pool_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_Pool_Int8TypeTable();
  }
  int32_t padX() const {
    return GetField<int32_t>(4, 0);
  }
  int32_t padY() const {
    return GetField<int32_t>(6, 0);
  }
  bool isGlobal() const {
    return GetField<uint8_t>(8, 0) != 0;
  }
  int32_t kernelX() const {
    return GetField<int32_t>(10, 0);
  }
  int32_t kernelY() const {
    return GetField<int32_t>(12, 0);
  }
  int32_t strideX() const {
    return GetField<int32_t>(14, 0);
  }
  int32_t strideY() const {
    return GetField<int32_t>(16, 0);
  }
  PoolType type() const {
    return static_cast<PoolType>(GetField<int8_t>(18, 0));
  }
  PoolPadType padType() const {
    return static_cast<PoolPadType>(GetField<int8_t>(20, 0));
  }
  DataType dataType() const {
    return static_cast<DataType>(GetField<int32_t>(22, 1));
  }
  bool ceilModel() const {
    return GetField<uint8_t>(24, 1) != 0;
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(26);
  }
  AvgPoolCountType countType() const {
    return static_cast<AvgPoolCountType>(GetField<int8_t>(28, 0));
  }
  int32_t ow() const {
    return GetField<int32_t>(30, 0);
  }
  int32_t oh() const {
    return GetField<int32_t>(32, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, 4) &&
           VerifyField<int32_t>(verifier, 6) &&
           VerifyField<uint8_t>(verifier, 8) &&
           VerifyField<int32_t>(verifier, 10) &&
           VerifyField<int32_t>(verifier, 12) &&
           VerifyField<int32_t>(verifier, 14) &&
           VerifyField<int32_t>(verifier, 16) &&
           VerifyField<int8_t>(verifier, 18) &&
           VerifyField<int8_t>(verifier, 20) &&
           VerifyField<int32_t>(verifier, 22) &&
           VerifyField<uint8_t>(verifier, 24) &&
           VerifyOffset(verifier, 26) &&
           verifier.VerifyVector(pads()) &&
           VerifyField<int8_t>(verifier, 28) &&
           VerifyField<int32_t>(verifier, 30) &&
           VerifyField<int32_t>(verifier, 32) &&
           verifier.EndTable();
  }
  NITI_Pool_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_Pool_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_Pool_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Pool_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_Pool_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_padX(int32_t padX) {
    fbb_.AddElement<int32_t>(4, padX, 0);
  }
  void add_padY(int32_t padY) {
    fbb_.AddElement<int32_t>(6, padY, 0);
  }
  void add_isGlobal(bool isGlobal) {
    fbb_.AddElement<uint8_t>(8, static_cast<uint8_t>(isGlobal), 0);
  }
  void add_kernelX(int32_t kernelX) {
    fbb_.AddElement<int32_t>(10, kernelX, 0);
  }
  void add_kernelY(int32_t kernelY) {
    fbb_.AddElement<int32_t>(12, kernelY, 0);
  }
  void add_strideX(int32_t strideX) {
    fbb_.AddElement<int32_t>(14, strideX, 0);
  }
  void add_strideY(int32_t strideY) {
    fbb_.AddElement<int32_t>(16, strideY, 0);
  }
  void add_type(PoolType type) {
    fbb_.AddElement<int8_t>(18, static_cast<int8_t>(type), 0);
  }
  void add_padType(PoolPadType padType) {
    fbb_.AddElement<int8_t>(20, static_cast<int8_t>(padType), 0);
  }
  void add_dataType(DataType dataType) {
    fbb_.AddElement<int32_t>(22, static_cast<int32_t>(dataType), 1);
  }
  void add_ceilModel(bool ceilModel) {
    fbb_.AddElement<uint8_t>(24, static_cast<uint8_t>(ceilModel), 1);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(26, pads);
  }
  void add_countType(AvgPoolCountType countType) {
    fbb_.AddElement<int8_t>(28, static_cast<int8_t>(countType), 0);
  }
  void add_ow(int32_t ow) {
    fbb_.AddElement<int32_t>(30, ow, 0);
  }
  void add_oh(int32_t oh) {
    fbb_.AddElement<int32_t>(32, oh, 0);
  }
  explicit NITI_Pool_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_Pool_Int8Builder &operator=(const NITI_Pool_Int8Builder &);
  flatbuffers::Offset<NITI_Pool_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_Pool_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_Pool_Int8> CreateNITI_Pool_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t padX = 0,
    int32_t padY = 0,
    bool isGlobal = false,
    int32_t kernelX = 0,
    int32_t kernelY = 0,
    int32_t strideX = 0,
    int32_t strideY = 0,
    PoolType type = PoolType_MAXPOOL,
    PoolPadType padType = PoolPadType_CAFFE,
    DataType dataType = DataType_DT_FLOAT,
    bool ceilModel = true,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    AvgPoolCountType countType = AvgPoolCountType_DEFAULT,
    int32_t ow = 0,
    int32_t oh = 0) {
  NITI_Pool_Int8Builder builder_(_fbb);
  builder_.add_oh(oh);
  builder_.add_ow(ow);
  builder_.add_pads(pads);
  builder_.add_dataType(dataType);
  builder_.add_strideY(strideY);
  builder_.add_strideX(strideX);
  builder_.add_kernelY(kernelY);
  builder_.add_kernelX(kernelX);
  builder_.add_padY(padY);
  builder_.add_padX(padX);
  builder_.add_countType(countType);
  builder_.add_ceilModel(ceilModel);
  builder_.add_padType(padType);
  builder_.add_type(type);
  builder_.add_isGlobal(isGlobal);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_Pool_Int8> CreateNITI_Pool_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Pool_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_ELTWISE_Int8T : public flatbuffers::NativeTable {
  typedef NITI_ELTWISE_Int8 TableType;
  EltwiseType type;
  NITI_ELTWISE_Int8T()
      : type(EltwiseType_PROD) {
  }
};

struct NITI_ELTWISE_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_ELTWISE_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_ELTWISE_Int8TypeTable();
  }
  EltwiseType type() const {
    return static_cast<EltwiseType>(GetField<int8_t>(4, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, 4) &&
           verifier.EndTable();
  }
  NITI_ELTWISE_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_ELTWISE_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_ELTWISE_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_ELTWISE_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_ELTWISE_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(EltwiseType type) {
    fbb_.AddElement<int8_t>(4, static_cast<int8_t>(type), 0);
  }
  explicit NITI_ELTWISE_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_ELTWISE_Int8Builder &operator=(const NITI_ELTWISE_Int8Builder &);
  flatbuffers::Offset<NITI_ELTWISE_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_ELTWISE_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_ELTWISE_Int8> CreateNITI_ELTWISE_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    EltwiseType type = EltwiseType_PROD) {
  NITI_ELTWISE_Int8Builder builder_(_fbb);
  builder_.add_type(type);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_ELTWISE_Int8> CreateNITI_ELTWISE_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_ELTWISE_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_LOSS_Int8T : public flatbuffers::NativeTable {
  typedef NITI_LOSS_Int8 TableType;
  int32_t batch;
  int32_t channel;
  int32_t height;
  int32_t width;
  NITI_LOSS_Int8T()
      : batch(0),
        channel(0),
        height(0),
        width(0) {
  }
};

struct NITI_LOSS_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_LOSS_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_LOSS_Int8TypeTable();
  }
  int32_t batch() const {
    return GetField<int32_t>(4, 0);
  }
  int32_t channel() const {
    return GetField<int32_t>(6, 0);
  }
  int32_t height() const {
    return GetField<int32_t>(8, 0);
  }
  int32_t width() const {
    return GetField<int32_t>(10, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, 4) &&
           VerifyField<int32_t>(verifier, 6) &&
           VerifyField<int32_t>(verifier, 8) &&
           VerifyField<int32_t>(verifier, 10) &&
           verifier.EndTable();
  }
  NITI_LOSS_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_LOSS_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_LOSS_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_LOSS_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_LOSS_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_batch(int32_t batch) {
    fbb_.AddElement<int32_t>(4, batch, 0);
  }
  void add_channel(int32_t channel) {
    fbb_.AddElement<int32_t>(6, channel, 0);
  }
  void add_height(int32_t height) {
    fbb_.AddElement<int32_t>(8, height, 0);
  }
  void add_width(int32_t width) {
    fbb_.AddElement<int32_t>(10, width, 0);
  }
  explicit NITI_LOSS_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_LOSS_Int8Builder &operator=(const NITI_LOSS_Int8Builder &);
  flatbuffers::Offset<NITI_LOSS_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_LOSS_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_LOSS_Int8> CreateNITI_LOSS_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t batch = 0,
    int32_t channel = 0,
    int32_t height = 0,
    int32_t width = 0) {
  NITI_LOSS_Int8Builder builder_(_fbb);
  builder_.add_width(width);
  builder_.add_height(height);
  builder_.add_channel(channel);
  builder_.add_batch(batch);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_LOSS_Int8> CreateNITI_LOSS_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_LOSS_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NITI_PAD_Int8T : public flatbuffers::NativeTable {
  typedef NITI_PAD_Int8 TableType;
  int32_t pad;
  NITI_PAD_Int8T()
      : pad(0) {
  }
};

struct NITI_PAD_Int8 FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NITI_PAD_Int8T NativeTableType;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NITI_PAD_Int8TypeTable();
  }
  int32_t pad() const {
    return GetField<int32_t>(4, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, 4) &&
           verifier.EndTable();
  }
  NITI_PAD_Int8T *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NITI_PAD_Int8T *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<NITI_PAD_Int8> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_PAD_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NITI_PAD_Int8Builder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_pad(int32_t pad) {
    fbb_.AddElement<int32_t>(4, pad, 0);
  }
  explicit NITI_PAD_Int8Builder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NITI_PAD_Int8Builder &operator=(const NITI_PAD_Int8Builder &);
  flatbuffers::Offset<NITI_PAD_Int8> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<NITI_PAD_Int8>(end);
    return o;
  }
};

inline flatbuffers::Offset<NITI_PAD_Int8> CreateNITI_PAD_Int8(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t pad = 0) {
  NITI_PAD_Int8Builder builder_(_fbb);
  builder_.add_pad(pad);
  return builder_.Finish();
}

flatbuffers::Offset<NITI_PAD_Int8> CreateNITI_PAD_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_PAD_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline TensorConvertInfoT *TensorConvertInfo::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new TensorConvertInfoT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void TensorConvertInfo::UnPackTo(TensorConvertInfoT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = source(); _o->source = _e; };
  { auto _e = dest(); _o->dest = _e; };
}

inline flatbuffers::Offset<TensorConvertInfo> TensorConvertInfo::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateTensorConvertInfo(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<TensorConvertInfo> CreateTensorConvertInfo(flatbuffers::FlatBufferBuilder &_fbb, const TensorConvertInfoT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const TensorConvertInfoT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _source = _o->source;
  auto _dest = _o->dest;
  return MNN::CreateTensorConvertInfo(
      _fbb,
      _source,
      _dest);
}

inline GridSampleT *GridSample::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new GridSampleT();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void GridSample::UnPackTo(GridSampleT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = mode(); _o->mode = _e; };
  { auto _e = paddingMode(); _o->paddingMode = _e; };
  { auto _e = alignCorners(); _o->alignCorners = _e; };
}

inline flatbuffers::Offset<GridSample> GridSample::Pack(flatbuffers::FlatBufferBuilder &_fbb, const GridSampleT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateGridSample(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<GridSample> CreateGridSample(flatbuffers::FlatBufferBuilder &_fbb, const GridSampleT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const GridSampleT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _mode = _o->mode;
  auto _paddingMode = _o->paddingMode;
  auto _alignCorners = _o->alignCorners;
  return MNN::CreateGridSample(
      _fbb,
      _mode,
      _paddingMode,
      _alignCorners);
}

inline NITI_CONV_Int8T *NITI_CONV_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_CONV_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_CONV_Int8::UnPackTo(NITI_CONV_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = common(); if (_e) _o->common = std::unique_ptr<Convolution2DCommonT>(_e->UnPack(_resolver)); };
  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } };
  { auto _e = wscale(); _o->wscale = _e; };
  { auto _e = nbits(); _o->nbits = _e; };
}

inline flatbuffers::Offset<NITI_CONV_Int8> NITI_CONV_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_CONV_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_CONV_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_CONV_Int8> CreateNITI_CONV_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_CONV_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_CONV_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _common = _o->common ? CreateConvolution2DCommon(_fbb, _o->common.get(), _rehasher) : 0;
  auto _weight = _o->weight.size() ? _fbb.CreateVector(_o->weight) : 0;
  auto _wscale = _o->wscale;
  auto _nbits = _o->nbits;
  return MNN::CreateNITI_CONV_Int8(
      _fbb,
      _common,
      _weight,
      _wscale,
      _nbits);
}

inline NITI_Relu_Int8T *NITI_Relu_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_Relu_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_Relu_Int8::UnPackTo(NITI_Relu_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = dataType(); _o->dataType = _e; };
}

inline flatbuffers::Offset<NITI_Relu_Int8> NITI_Relu_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Relu_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_Relu_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_Relu_Int8> CreateNITI_Relu_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Relu_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_Relu_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _dataType = _o->dataType;
  return MNN::CreateNITI_Relu_Int8(
      _fbb,
      _dataType);
}

inline NITI_Pool_Int8T *NITI_Pool_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_Pool_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_Pool_Int8::UnPackTo(NITI_Pool_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = padX(); _o->padX = _e; };
  { auto _e = padY(); _o->padY = _e; };
  { auto _e = isGlobal(); _o->isGlobal = _e; };
  { auto _e = kernelX(); _o->kernelX = _e; };
  { auto _e = kernelY(); _o->kernelY = _e; };
  { auto _e = strideX(); _o->strideX = _e; };
  { auto _e = strideY(); _o->strideY = _e; };
  { auto _e = type(); _o->type = _e; };
  { auto _e = padType(); _o->padType = _e; };
  { auto _e = dataType(); _o->dataType = _e; };
  { auto _e = ceilModel(); _o->ceilModel = _e; };
  { auto _e = pads(); if (_e) { _o->pads.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->pads[_i] = _e->Get(_i); } } };
  { auto _e = countType(); _o->countType = _e; };
  { auto _e = ow(); _o->ow = _e; };
  { auto _e = oh(); _o->oh = _e; };
}

inline flatbuffers::Offset<NITI_Pool_Int8> NITI_Pool_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Pool_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_Pool_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_Pool_Int8> CreateNITI_Pool_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_Pool_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_Pool_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _padX = _o->padX;
  auto _padY = _o->padY;
  auto _isGlobal = _o->isGlobal;
  auto _kernelX = _o->kernelX;
  auto _kernelY = _o->kernelY;
  auto _strideX = _o->strideX;
  auto _strideY = _o->strideY;
  auto _type = _o->type;
  auto _padType = _o->padType;
  auto _dataType = _o->dataType;
  auto _ceilModel = _o->ceilModel;
  auto _pads = _o->pads.size() ? _fbb.CreateVector(_o->pads) : 0;
  auto _countType = _o->countType;
  auto _ow = _o->ow;
  auto _oh = _o->oh;
  return MNN::CreateNITI_Pool_Int8(
      _fbb,
      _padX,
      _padY,
      _isGlobal,
      _kernelX,
      _kernelY,
      _strideX,
      _strideY,
      _type,
      _padType,
      _dataType,
      _ceilModel,
      _pads,
      _countType,
      _ow,
      _oh);
}

inline NITI_ELTWISE_Int8T *NITI_ELTWISE_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_ELTWISE_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_ELTWISE_Int8::UnPackTo(NITI_ELTWISE_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = type(); _o->type = _e; };
}

inline flatbuffers::Offset<NITI_ELTWISE_Int8> NITI_ELTWISE_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_ELTWISE_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_ELTWISE_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_ELTWISE_Int8> CreateNITI_ELTWISE_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_ELTWISE_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_ELTWISE_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _type = _o->type;
  return MNN::CreateNITI_ELTWISE_Int8(
      _fbb,
      _type);
}

inline NITI_LOSS_Int8T *NITI_LOSS_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_LOSS_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_LOSS_Int8::UnPackTo(NITI_LOSS_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = batch(); _o->batch = _e; };
  { auto _e = channel(); _o->channel = _e; };
  { auto _e = height(); _o->height = _e; };
  { auto _e = width(); _o->width = _e; };
}

inline flatbuffers::Offset<NITI_LOSS_Int8> NITI_LOSS_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_LOSS_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_LOSS_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_LOSS_Int8> CreateNITI_LOSS_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_LOSS_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_LOSS_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _batch = _o->batch;
  auto _channel = _o->channel;
  auto _height = _o->height;
  auto _width = _o->width;
  return MNN::CreateNITI_LOSS_Int8(
      _fbb,
      _batch,
      _channel,
      _height,
      _width);
}

inline NITI_PAD_Int8T *NITI_PAD_Int8::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = new NITI_PAD_Int8T();
  UnPackTo(_o, _resolver);
  return _o;
}

inline void NITI_PAD_Int8::UnPackTo(NITI_PAD_Int8T *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = pad(); _o->pad = _e; };
}

inline flatbuffers::Offset<NITI_PAD_Int8> NITI_PAD_Int8::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NITI_PAD_Int8T* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNITI_PAD_Int8(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<NITI_PAD_Int8> CreateNITI_PAD_Int8(flatbuffers::FlatBufferBuilder &_fbb, const NITI_PAD_Int8T *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NITI_PAD_Int8T* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _pad = _o->pad;
  return MNN::CreateNITI_PAD_Int8(
      _fbb,
      _pad);
}

inline const flatbuffers::TypeTable *SampleModeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    SampleModeTypeTable
  };
  static const char * const names[] = {
    "BILINEAR",
    "NEAREST"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 2, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *BorderModeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    BorderModeTypeTable
  };
  static const char * const names[] = {
    "ZEROS",
    "CLAMP",
    "REFLECTION"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *TensorConvertInfoTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN_DATA_FORMATTypeTable
  };
  static const char * const names[] = {
    "source",
    "dest"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *GridSampleTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 1 },
    { flatbuffers::ET_BOOL, 0, -1 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    SampleModeTypeTable,
    BorderModeTypeTable
  };
  static const char * const names[] = {
    "mode",
    "paddingMode",
    "alignCorners"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 3, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_CONV_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_CHAR, 1, -1 },
    { flatbuffers::ET_CHAR, 0, -1 },
    { flatbuffers::ET_CHAR, 0, -1 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    Convolution2DCommonTypeTable
  };
  static const char * const names[] = {
    "common",
    "weight",
    "wscale",
    "nbits"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_Relu_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    DataTypeTypeTable
  };
  static const char * const names[] = {
    "dataType"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_Pool_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 1 },
    { flatbuffers::ET_INT, 0, 2 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_CHAR, 0, 3 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    PoolTypeTypeTable,
    PoolPadTypeTypeTable,
    DataTypeTypeTable,
    AvgPoolCountTypeTypeTable
  };
  static const char * const names[] = {
    "padX",
    "padY",
    "isGlobal",
    "kernelX",
    "kernelY",
    "strideX",
    "strideY",
    "type",
    "padType",
    "dataType",
    "ceilModel",
    "pads",
    "countType",
    "ow",
    "oh"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 15, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_ELTWISE_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    EltwiseTypeTypeTable
  };
  static const char * const names[] = {
    "type"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 1, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_LOSS_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 }
  };
  static const char * const names[] = {
    "batch",
    "channel",
    "height",
    "width"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NITI_PAD_Int8TypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 }
  };
  static const char * const names[] = {
    "pad"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
  };
  return &tt;
}

}  // namespace MNN

#endif  // FLATBUFFERS_GENERATED_USERDEFINE_MNN_H_
